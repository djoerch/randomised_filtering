{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK TRAINING CODE ##\n",
    "\n",
    "This module contains all code used for network training (aside from helper/data loader functions) and basic evaluations\n",
    "\n",
    "Author: antoniabhain@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import streamline_loader\n",
    "\n",
    "TRK_PATH = \"data/599671/All_10M_corrected.trk\"\n",
    "POS_STREAMLINES_PATH = \"data/599671/json/pos_streamlines.json\"\n",
    "NEG_STREAMLINES_PATH = \"data/599671/json/neg_streamlines.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_streamlines, neg_streamlines, inc_streamlines = streamline_loader.load_data(\n",
    "    TRK_PATH, \n",
    "    POS_STREAMLINES_PATH,  \n",
    "    NEG_STREAMLINES_PATH, \n",
    "    normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(pos_streamlines)\n",
    "np.random.shuffle(neg_streamlines)\n",
    "np.random.shuffle(inc_streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resize data to fit network input dimensions\n",
    "pos_resized = np.array([cv2.resize(x, (3,23)).reshape((69,1)) for x in pos_streamlines])\n",
    "neg_resized = np.array([cv2.resize(x, (3,23)).reshape((69,1)) for x in neg_streamlines])\n",
    "inc_resized = np.array([cv2.resize(x, (3,23)).reshape((69,1)) for x in inc_streamlines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BalancedDataGen(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, data, weights, batch_size, categorical=False):\n",
    "        \n",
    "        # copy to avoid messing up original data order through np.shuffle\n",
    "        self._data = [d.copy() for d in data] \n",
    "        self._num_classes = len(data)\n",
    "        \n",
    "        if len(weights) != self._num_classes:\n",
    "            raise ValueError(\"Please provide weight for each class\")\n",
    "        \n",
    "        self._weights = weights\n",
    "        \n",
    "        if (batch_size % self._num_classes != 0):\n",
    "            raise ValueError(\"Please make batch size dividable by number of classes\")\n",
    "        \n",
    "        self._batch_size = batch_size\n",
    "        self._subbatch_size = batch_size // self._num_classes\n",
    "        \n",
    "        self._batches = [int(len(x) // self._subbatch_size) for x in self._data]\n",
    "        \n",
    "        self._categorical = categorical\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "     \n",
    "    def on_epoch_end(self):\n",
    "        for d in self._data:\n",
    "            np.random.shuffle(d)\n",
    "            \n",
    "    def _get_subbatch(self, class_idx, idx):\n",
    "        # class_idx is the index for the class. so self._data[class_idx] will be used\n",
    "        \n",
    "        data_idx = np.array(idx % self._batches[class_idx])\n",
    "        class_data = self._data[class_idx]\n",
    "    \n",
    "        x = class_data[data_idx * self._subbatch_size:\n",
    "                       data_idx * self._subbatch_size + self._subbatch_size]\n",
    "        y = np.full(self._subbatch_size, class_idx)\n",
    "        w = np.full(self._subbatch_size, self._weights[class_idx])\n",
    "        \n",
    "        # shuffle the data-subset if epoch is not over but data is exhausted (for under-represented subsets)\n",
    "        if data_idx == self._batches[class_idx] - 1:\n",
    "            np.random.shuffle(self._data[class_idx])\n",
    "        \n",
    "        return x,y,w\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        w = []\n",
    "        \n",
    "        # compile parts of batch from all streamline classes\n",
    "        for i in range(self._num_classes):\n",
    "            x_tmp, y_tmp, w_tmp = self._get_subbatch(i, idx)\n",
    "            x.append(x_tmp)\n",
    "            y.append(y_tmp)\n",
    "            w.append(w_tmp)\n",
    "            \n",
    "        x = np.concatenate(x, axis=0)\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        w = np.concatenate(w, axis=0)\n",
    "        \n",
    "        if self._categorical:\n",
    "            y = tf.keras.utils.to_categorical(y, num_classes=self._num_classes, dtype='float32')\n",
    "\n",
    "        return x, y, w\n",
    "            \n",
    "    def __len__(self):\n",
    "        return max(self._batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical crossentropy model\n",
    "def get_categorical_model(num_classes):\n",
    "    # returns multi-class model with given number of classes\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer(input_shape=(69,1)),\n",
    "            keras.layers.Conv1D(8, kernel_size=5, padding='same', activation=\"relu\"),\n",
    "            keras.layers.MaxPooling1D(pool_size=2),\n",
    "            keras.layers.Conv1D(16, kernel_size=3, padding='same', activation=\"relu\"),\n",
    "            keras.layers.MaxPooling1D(pool_size=2),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def get_binary_model():\n",
    "    # returns binary model\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer(input_shape=(69,1)),\n",
    "            keras.layers.Conv1D(8, kernel_size=5, padding='same', activation=\"relu\"),\n",
    "            keras.layers.MaxPooling1D(pool_size=2),\n",
    "            keras.layers.Conv1D(16, kernel_size=3, padding='same', activation=\"relu\"),\n",
    "            keras.layers.MaxPooling1D(pool_size=2),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAUSIBLE VS IMPLAUSIBLE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "k = 5\n",
    "\n",
    "# exchange one of these for inc_resized when wanting to train with inconclusive streamlines\n",
    "data = [neg_resized, pos_resized]\n",
    "fold_len = [int(len(d)/k) for d in data]\n",
    "\n",
    "# train 5 models for cross-validation\n",
    "for fold in range(k):\n",
    "\n",
    "    # generate masks that cut out the data folds\n",
    "    test_mask = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        tmp_mask = np.zeros(len(data[i]), dtype=np.bool)\n",
    "        tmp_mask[int(fold * fold_len[i]):int((fold+1) * fold_len[i])] = True\n",
    "        test_mask += [tmp_mask]\n",
    "    \n",
    "    train_mask = [np.invert(m) for m in test_mask]\n",
    "    \n",
    "    print(\"MODEL\", fold)\n",
    "    traingen_pn = BalancedDataGen([data[0][train_mask[0]], \n",
    "                              data[1][train_mask[1]]],\n",
    "                              [1, 1], BATCH_SIZE)   \n",
    "    testgen_pn = BalancedDataGen([data[0][test_mask[0]], \n",
    "                              data[1][test_mask[1]]],\n",
    "                              [1, 1], BATCH_SIZE)                                        \n",
    "\n",
    "    model = get_binary_model()\n",
    "    model.fit(traingen_pn, epochs=5, verbose=1)\n",
    "    model.evaluate(testgen_pn, verbose=1)\n",
    "    \n",
    "    correct_predictions_0 = 1 - np.sum(np.round(model.predict(data[0][test_mask[0]]))) / len(data[0])\n",
    "    print(correct_predictions_0)\n",
    "    print(len(data[0]))\n",
    "    print()\n",
    "\n",
    "    correct_predictions_1 = np.sum(np.round(model.predict(data[1][test_mask[1]]))) / len(data[1])\n",
    "    print(len(data[1]))\n",
    "    print()\n",
    "    \n",
    "    model.save(\"model_binary_\"+str(fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI-CLASS CLASSIFIER ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 60\n",
    "k = 5\n",
    "\n",
    "data = [neg_resized, pos_resized, inc_resized]\n",
    "fold_len = [int(len(d)/k) for d in data]\n",
    "\n",
    "for fold in range(k):\n",
    "\n",
    "    # generate masks that cut out the data folds\n",
    "    test_mask = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        tmp_mask = np.zeros(len(data[i]), dtype=np.bool)\n",
    "        tmp_mask[int(fold * fold_len[i]):int((fold+1) * fold_len[i])] = True\n",
    "        test_mask += [tmp_mask]\n",
    "    \n",
    "    train_mask = [np.invert(m) for m in test_mask]\n",
    "    \n",
    "    traingen_cat3 = BalancedDataGen([data[0][train_mask[0]], \n",
    "                              data[1][train_mask[1]],\n",
    "                              data[2][train_mask[2]]],\n",
    "                               [1, 1, 1], BATCH_SIZE, categorical=True)   \n",
    "    testgen_cat3 = BalancedDataGen([data[0][train_mask[0]], \n",
    "                              data[1][train_mask[1]],\n",
    "                              data[2][train_mask[2]]],\n",
    "                              [1, 1, 1], BATCH_SIZE, categorical=True)                                        \n",
    "\n",
    "    print(\"MODEL\", fold)\n",
    "    model_cat3 = get_categorical_model(3)\n",
    " \n",
    "    model_cat3.fit(traingen_cat3, epochs=2, verbose=1)\n",
    "    model_cat3.evaluate(testgen_cat3, verbose=1)\n",
    "      \n",
    "    model_cat3.save(\"model_cat3_\"+str(fold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
